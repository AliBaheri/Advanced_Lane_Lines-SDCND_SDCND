{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ali/Dropbox/MOOC/Self_Driving_Car_Nanodegree_UDACITY/Advanced_Lane_Lines-SDCND\n"
     ]
    }
   ],
   "source": [
    "cd /Users/ali/Dropbox/MOOC/Self_Driving_Car_Nanodegree_UDACITY/Advanced_Lane_Lines-SDCND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mREADME.md\u001b[m\u001b[m*                  \u001b[31mharder_challenge_video.mp4\u001b[m\u001b[m*\r\n",
      "\u001b[34mcamera_cal\u001b[m\u001b[m/                 \u001b[34moutput_images\u001b[m\u001b[m/\r\n",
      "\u001b[31mchallenge_video.mp4\u001b[m\u001b[m*        \u001b[31mproject_video.mp4\u001b[m\u001b[m*\r\n",
      "\u001b[31mexample_writeup.pdf\u001b[m\u001b[m*        \u001b[34mtest_images\u001b[m\u001b[m/\r\n",
      "\u001b[34mexamples\u001b[m\u001b[m/                   \u001b[31mwriteup_template.md\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "# arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3D points in real world space\n",
    "imgpoints = [] # 2D points in image plane\n",
    "\n",
    "# prepare object points\n",
    "objp = np.zeros((6*9, 3), np.float32) # same 3D from (0,0,0) to (7,5,0)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # x,y coord; mgrid returns coord values \n",
    "\n",
    "images = glob.glob('/camera_cal/calibration*.jpg')\n",
    "\n",
    "for _, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    if ret == True:\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "        # draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "        ax1.imshow(cv2.cvtColor(mpimg.imread(fname), cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Original Image', fontsize=15)\n",
    "        ax2.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Corners Image', fontsize=15)        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistorted_correction(img, objpoints, imgpoints):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "for _, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    undistorted = undistorted_correction(img, objpoints, imgpoints)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize = (10,5))\n",
    "    ax1.imshow(cv2.cvtColor(mpimg.imread(fname), cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Original Image', fontsize = 15)\n",
    "    ax2.imshow(cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB))\n",
    "    ax2.set_title('Undistorted Image', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/Users/jenkins/miniconda/0/2.7/conda-bld/work/opencv-2.4.11/modules/calib3d/src/calibration.cpp:3415: error: (-215) nimages > 0 in function calibrateCamera\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4b2d4354332b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mundistorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mundistorted_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-50d3ca12874a>\u001b[0m in \u001b[0;36mundistorted_correction\u001b[0;34m(img, objpoints, imgpoints)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mundistorted_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mundist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mundist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/jenkins/miniconda/0/2.7/conda-bld/work/opencv-2.4.11/modules/calib3d/src/calibration.cpp:3415: error: (-215) nimages > 0 in function calibrateCamera\n"
     ]
    }
   ],
   "source": [
    "test_images = glob.glob('test_images/*.jpg')\n",
    "for _, fname in enumerate(test_images):\n",
    "    img = cv2.imread(fname)\n",
    "    undistorted = undistorted_correction(img, objpoints, imgpoints)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(6,3))\n",
    "    ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Original Image', fontsize=15)\n",
    "    ax2.imshow(cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB))\n",
    "    ax2.set_title('Undistorted Image', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'COLOR_RGB2Lab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ac421ad19b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mluv_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLUV_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mlightness_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlightness_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mlab_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLAB_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m155\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mcombined_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_gradient_thresholds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ac421ad19b22>\u001b[0m in \u001b[0;36mLAB_thresh\u001b[0;34m(img, thresh)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mLAB_thresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2Lab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert RGB to floating-point format and scaled to fit the 0 to 1 range.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mlab2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlab_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'COLOR_RGB2Lab'"
     ]
    }
   ],
   "source": [
    "img = mpimg.imread('test_images/test3.jpg')\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0,255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) \n",
    "    if orient=='x': abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient=='y': abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel)) # rescale 8-bit\n",
    "    sobel_binary = np.zeros_like(scaled_sobel) # create a copy and apply threshold\n",
    "    sobel_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return sobel_binary\n",
    "\n",
    "def HLS_thresh(img, thresh=(0, 255)): # (170,255) (150,255) (180, 255)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    ch = hls[:,:,2] # saturation\n",
    "    hls_binary = np.zeros_like(ch)\n",
    "    hls_binary[(ch > thresh[0]) & (ch <= thresh[1])] = 1\n",
    "    return hls_binary\n",
    "\n",
    "def HSV_thresh(img, channel='v', thresh=(0,255)):\n",
    "    hsv = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "    if channel=='v': ch = hsv[:,:,2] # value\n",
    "    if channel=='s': ch = hsv[:,:,1] # saturation\n",
    "    hsv_binary = np.zeros_like(ch)\n",
    "    hsv_binary[(ch > thresh[0]) & (ch <= thresh[1])] = 1\n",
    "    return hsv_binary\n",
    "\n",
    "def LUV_thresh(img, thresh=(0,255)):\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    ch = luv[:,:,0] \n",
    "    luv_binary = np.zeros_like(ch)\n",
    "    luv_binary[(ch >= thresh[0]) & (ch <= thresh[1])]\n",
    "    return luv_binary\n",
    "\n",
    "def LAB_thresh(img, thresh=(0,255)):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab) # convert RGB to floating-point format and scaled to fit the 0 to 1 range.\n",
    "    lab2 = lab[:,:,2]\n",
    "    lab_binary = np.zeros_like(lab2)\n",
    "    lab_binary[((lab2 >= thresh[0]) & (lab2 <= thresh[1]))] = 1\n",
    "    return lab_binary\n",
    "\n",
    "def lightness_mask(img, thresh=(0,255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    saturation = hls[:,:,2]\n",
    "    lightness = hls[:,:,1]\n",
    "    lightness_binary = np.zeros_like(saturation)\n",
    "    lightness_binary[(saturation >=thresh[0]) & (lightness>=thresh[1])] = 1\n",
    "    return lightness_binary\n",
    "\n",
    "def combined_gradient_thresholds(img): # img: undistorted image\n",
    "    sobelx_binary = abs_sobel_thresh(img, orient='x', sobel_kernel=5, thresh=(30,90))\n",
    "    sobely_binary = abs_sobel_thresh(img, orient='y', sobel_kernel=5, thresh=(30,90))\n",
    "    saturation_binary = HLS_thresh(img, thresh=(120,255))\n",
    "    value_HSV_binary = HSV_thresh(img, channel='v', thresh=(75,255))\n",
    "    saturation_HSV_binary = HSV_thresh(img, channel='s', thresh=(120,255))\n",
    "    #luv_binary = LUV_thresh(img, thresh=(225,255))\n",
    "    lightness_binary = lightness_mask(img, thresh=(5,130))\n",
    "    #lab_binary = LAB_thresh(img, thresh=(155,200))\n",
    "    combined_binary = np.zeros_like(sobelx_binary)\n",
    "    combined_binary[(saturation_HSV_binary==1) | (sobelx_binary==1) | (sobely_binary==1) & (value_HSV_binary==1) | (lightness_binary==1)]=1 ## \n",
    "    return combined_binary\n",
    "\n",
    "\n",
    "sobelx_binary = abs_sobel_thresh(img, orient='x', sobel_kernel=5, thresh=(30,90))\n",
    "sobely_binary = abs_sobel_thresh(img, orient='y', sobel_kernel=5, thresh=(30,90))\n",
    "\n",
    "saturation_binary = HLS_thresh(img, thresh=(120,255))\n",
    "value_HSV_binary = HSV_thresh(img, channel='v', thresh=(75,255))\n",
    "saturation_HSV_binary = HSV_thresh(img, channel='s', thresh=(120,255))\n",
    "\n",
    "luv_binary = LUV_thresh(img, thresh=(30,12))\n",
    "lightness_binary = lightness_mask(img, thresh=(5,130))\n",
    "lab_binary = LAB_thresh(img, thresh=(155,200))\n",
    "combined_binary = combined_gradient_thresholds(img)\n",
    "\n",
    "\n",
    "\n",
    "f, ((ax1, ax2),(ax3, ax4)) = plt.subplots(2, 2, figsize=(10,5))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=12)\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(sobelx_binary, cmap='gray')\n",
    "ax2.set_title('sobelx_binary', fontsize=12)\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3.imshow(sobely_binary, cmap='gray')\n",
    "ax3.set_title('sobely_binary', fontsize=12)\n",
    "ax3.axis('off')\n",
    "\n",
    "ax4.imshow(saturation_binary, cmap='gray')\n",
    "ax4.set_title('saturation_binary', fontsize=12)\n",
    "ax4.axis('off')\n",
    "\n",
    "f, ((ax5,ax6),(ax7,ax8)) = plt.subplots(2, 2, figsize=(10,5))\n",
    "ax5.imshow(value_HSV_binary, cmap='gray')\n",
    "ax5.set_title('value_HSV_binary', fontsize=12)\n",
    "ax5.axis('off')\n",
    "\n",
    "ax6.imshow(saturation_HSV_binary, cmap='gray')\n",
    "ax6.set_title('saturation_HSV_binary', fontsize=12)\n",
    "ax6.axis('off')\n",
    "\n",
    "ax7.imshow(lab_binary, cmap='gray')\n",
    "ax7.set_title('lab_binary', fontsize=12)\n",
    "ax7.axis('off')\n",
    "\n",
    "ax8.imshow(lightness_binary, cmap='gray')\n",
    "ax8.set_title('lightness_binary', fontsize=12)\n",
    "ax8.axis('off')\n",
    "\n",
    "f, (ax9) = plt.subplots(1, 1, figsize=(12,5))\n",
    "ax9.imshow(combined_binary, cmap='gray')\n",
    "ax9.set_title('combined_binary', fontsize=12)\n",
    "ax9.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perspective_transform(img, src, dst):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return M, Minv, warped\n",
    "def bird_eye_perspective(img, src, dst):\n",
    "    undist = undistorted_correction(img, objpoints, imgpoints) # undistorted image\n",
    "    M, Minv, warped = perspective_transform(undist, src, dst)\n",
    "    return M, Minv, warped, undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test3.jpg')\n",
    "\n",
    "src = np.float32([[585,460], [203,720],\n",
    "            [1127,720], [695,460]])\n",
    "dst = np.float32([[320,0], [320,720],\n",
    "            [960,720], [960,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M, Minv, warped = perspective_transform(img, src, dst)\n",
    "_, _, _, undist = bird_eye_perspective(img, src, dst)\n",
    "\n",
    "f, (ax0) = plt.subplots(1, 1, figsize=(12,5))\n",
    "ax0.imshow(img)\n",
    "ax0.set_title('Original Image', fontsize=12)\n",
    "ax0.axis('off')\n",
    "\n",
    "f, ((ax1, ax2),(ax3, ax4)) = plt.subplots(2, 2, figsize=(10,5))\n",
    "ax1.imshow(M)\n",
    "ax1.set_title('M', fontsize=12)\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(Minv)\n",
    "ax2.set_title('Minv', fontsize=12)\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3.imshow(warped, cmap='gray')\n",
    "ax3.set_title('warped', fontsize=12)\n",
    "ax3.axis('off')\n",
    "\n",
    "ax4.imshow(undist, cmap='gray')\n",
    "ax4.set_title('undist', fontsize=12)\n",
    "ax4.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_binary(img, src, dst):\n",
    "    M, Minv, warped, undist = bird_eye_perspective(img, src, dst) # warped image is undistorte and warped.\n",
    "    combined_binary = combined_gradient_thresholds(warped) # sobelx+saturation+value\n",
    "    return combined_binary, warped, M, Minv, undist\n",
    "\n",
    "combined_binary, warped, M, Minv, undist = apply_binary(img, src, dst)\n",
    "print(combined_binary.shape)\n",
    "\n",
    "f, (ax0) = plt.subplots(1, 1, figsize=(10,5))\n",
    "ax0.imshow(combined_binary, cmap='gray')\n",
    "ax0.set_title('combined_binary', fontsize=12)\n",
    "ax0.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lane_lines(combined_binary):\n",
    "    histogram = np.sum(combined_binary[combined_binary.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((combined_binary, combined_binary, combined_binary))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(combined_binary.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = combined_binary.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    global detected_line, left_fit, right_fit, left_fit_poly, right_fit_poly\n",
    "    for window in range(nwindows): \n",
    "        win_y_low = combined_binary.shape[0] - (window+1)*window_height\n",
    "        win_y_high = combined_binary.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "            # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "            (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "            (0,255,0), 2) \n",
    "            # \n",
    "\n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        \n",
    "        #Pixel position for left and right\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "        #Fit 2nd polynomial\n",
    "    left_fit = np.polyfit(lefty,leftx, 2)\n",
    "    right_fit = np.polyfit(righty,rightx,2)\n",
    "    \n",
    "    out_img[lefty, leftx] = [255,0,0]\n",
    "    out_img[righty,rightx] = [0,0,255]\n",
    "\n",
    "    ploty = np.linspace(0, combined_binary.shape[0]-1, combined_binary.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    \n",
    "    return out_img, left_lane_inds, right_lane_inds, leftx, lefty, rightx, righty, left_fit, right_fit, nonzerox, nonzeroy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global detected_line, left_fit, right_fit, left_fit_poly, right_fit_poly\n",
    "\n",
    "out_img, left_lane_inds, right_lane_inds, leftx, lefty, rightx, righty, left_fit, right_fit, nonzerox, nonzeroy = find_lane_lines(combined_binary)\n",
    "\n",
    "ploty = np.linspace(0, combined_binary.shape[0]-1, combined_binary.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "margin=100\n",
    "out_img = np.dstack((combined_binary, combined_binary, combined_binary))*255\n",
    "window_img = np.zeros_like(out_img)\n",
    "# Color in left and right line pixels\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(result)\n",
    "\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, unwarped = perspective_transform(result, dst, src)\n",
    "undist_cp = np.copy(undist)\n",
    "final = cv2.addWeighted(undist_cp, 1, unwarped,0.5,0)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.imshow(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_curvature(ploty, leftx, lefty, rightx, righty, left_fit, right_fit):\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30./720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    return (left_curverad, right_curverad)\n",
    "\n",
    "def get_center(img, ploty, left_fit, right_fit):\n",
    "    ymax = np.max(ploty)\n",
    "    xm_per_pix = 3.7/700 # meters per px in x-dim (conversions in x,y from pixels space to meters)\n",
    "    left = left_fit[0]*ymax**2 + left_fit[1]*ymax + left_fit[2]\n",
    "    right = right_fit[0]*ymax**2 + right_fit[1]*ymax + right_fit[2]\n",
    "    center = (left + right) / 2\n",
    "    return (img.shape[1]/2 - center)*xm_per_pix\n",
    "\n",
    "def draw_lines(img, leftx, lefty, rightx, righty):\n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    right_fit = np.polyfit(righty, rightx, 2) \n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "\n",
    "    left_points = np.vstack(([left_fitx.T], [lefty.T])).T\n",
    "    right_points = np.vstack(([right_fitx.T], [righty.T])).T\n",
    "    all_points = np.concatenate((left_points, right_points[::-1]))\n",
    "\n",
    "    cv2.fillConvexPoly(img, np.int32([all_points]), (0, 255, 0))\n",
    "    cv2.polylines(img, np.int32([left_points]), False, (255, 0, 0), 20)\n",
    "    cv2.polylines(img, np.int32([right_points]), False, (255, 0, 0), 20)        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline_process(img):\n",
    "    src = np.float32([[585,460], [203,720],\n",
    "            [1127,720], [695,460]])\n",
    "    dst = np.float32([[320,0], [320,720],\n",
    "            [960,720], [960,0]])\n",
    "\n",
    "    combined_binary, warped, M, Minv, undist = apply_binary(img, src, dst)\n",
    "    \n",
    "    global detected_line, left_fit, right_fit, left_fit_poly, right_fit_poly\n",
    "    \n",
    "    out_img, left_lane_inds, right_lane_inds, leftx, lefty, rightx, righty, left_fit, right_fit, nonzerox, nonzeroy = find_lane_lines(combined_binary)\n",
    "    \n",
    "    drawwarped = draw_lines(np.zeros_like(warped), leftx, lefty, rightx, righty)\n",
    "    _, _, unwarped = perspective_transform(drawwarped, dst, src)\n",
    "    output = cv2.addWeighted(undist, 1, unwarped, 0.3, 0.0)\n",
    "    \n",
    "    left_curverad, right_curverad = get_curvature(lefty, leftx, lefty, rightx, righty, left_fit, right_fit)\n",
    "    curvature = min([left_curverad, right_curverad])\n",
    "    text = \"Curvature of Radius: {:.2f} m\".format(curvature)\n",
    "    cv2.putText(output, text, (50,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    text1 = \"Left curve: {:.2f} m\".format(left_curverad)\n",
    "    cv2.putText(output, text1, (50,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    text1 = \"Right curve: {:.2f} m \".format(right_curverad)\n",
    "    cv2.putText(output, text1, (50,260), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    pos = get_center(img, ploty, left_fit, right_fit)\n",
    "    if pos < 0:\n",
    "        text = \"Vehicle is {:.2f} m on left\".format(-pos)\n",
    "    else:\n",
    "        text = \"Vehicle is {:.2f} m on right\".format(pos)\n",
    "    cv2.putText(output, text, (50,140), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_eval = np.max(ploty)\n",
    "left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30./720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # Fit new polynomials to x,y in world space\n",
    "\n",
    "left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_pipeline(img):\n",
    "    src = np.float32([[585,460], [203,720],\n",
    "            [1127,720], [695,460]])\n",
    "    dst = np.float32([[320,0], [320,720],\n",
    "            [960,720], [960,0]])\n",
    "\n",
    "    combined_binary, warped, M, Minv, undist = apply_binary(img, src, dst)\n",
    "    \n",
    "    global detected_line, left_fit, right_fit, left_fit_poly, right_fit_poly\n",
    "    \n",
    "    out_img, left_lane_inds, right_lane_inds, leftx, lefty, rightx, righty, left_fit, right_fit, nonzerox, nonzeroy = find_lane_lines(combined_binary)\n",
    "    \n",
    "    drawwarped = draw_lines(np.zeros_like(warped), leftx, lefty, rightx, righty)\n",
    "    _, _, unwarped = perspective_transform(drawwarped, dst, src)\n",
    "    output = cv2.addWeighted(undist, 1, unwarped, 0.3, 0.0)\n",
    "    \n",
    "    left_curverad, right_curverad = get_curvature(lefty, leftx, lefty, rightx, righty, left_fit, right_fit)\n",
    "    curvature = min([left_curverad, right_curverad])\n",
    "    text = \"Curvature of Radius: {:.2f} m\".format(curvature)\n",
    "    cv2.putText(output, text, (50,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    text1 = \"Left curve: {:.2f} m\".format(left_curverad)\n",
    "    cv2.putText(output, text1, (50,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (25,255,255), 2)\n",
    "    text1 = \"Right curve: {:.2f} m \".format(right_curverad)\n",
    "    cv2.putText(output, text1, (50,260), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    \n",
    "    pos = get_center(img, ploty, left_fit, right_fit)\n",
    "    if pos < 0:\n",
    "        text = \"Vehicle is {:.2f} m on left\".format(-pos)\n",
    "    else:\n",
    "        text = \"Vehicle is {:.2f} m on right\".format(pos)\n",
    "    cv2.putText(output, text, (50,140), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=  my_pipeline(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "project_output = 'AA.mp4'\n",
    "clip2 = VideoFileClip('project_video.mp4')\n",
    "\n",
    "global detected_line, left_fit, right_fit, left_fit_poly, right_fit_poly\n",
    "\n",
    "project_clip = clip2.fl_image(my_pipeline)\n",
    "#time project_clip.write_videofile(project_output, fps = 25, audio= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
